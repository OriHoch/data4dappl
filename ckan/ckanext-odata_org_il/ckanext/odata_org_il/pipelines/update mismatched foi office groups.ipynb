{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the ckan environment and requests session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, environ\n",
    "import requests\n",
    "from dataflows import Flow, load\n",
    "from datapackage_pipelines_ckanext.helpers import get_plugin_configuration\n",
    "\n",
    "config = get_plugin_configuration('odata_org_il')\n",
    "data_path = config['data_path']\n",
    "\n",
    "CKAN_API_KEY = environ.get('CKAN_API_KEY')\n",
    "CKAN_URL = environ.get('CKAN_URL')\n",
    "assert CKAN_API_KEY and CKAN_URL\n",
    "CKAN_AUTH_HEADERS = {'Authorization': CKAN_API_KEY}\n",
    "session = requests.session()\n",
    "session.headers.update(CKAN_AUTH_HEADERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflows import Flow, load\n",
    "import yaml\n",
    "from load_existing_entities import get_existing_entities_resource, get_existing_entities_resource_descriptor\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_odata_resource(name, resources=None):\n",
    "    path = f'{data_path}/{name}/datapackage.json'\n",
    "    print(f'Loading resource from {path}')\n",
    "    resource = Flow(load(path, resources=resources)).results()[0][0]\n",
    "    print(f'Resource loaded: {name} ({len(resource)} rows)')\n",
    "    return resource\n",
    "\n",
    "def yaml_print(data):\n",
    "    print(yaml.dump(data, allow_unicode=True, default_flow_style=False))\n",
    "\n",
    "def get_existing_entities_flow():\n",
    "    stats = defaultdict(int)\n",
    "    return Flow(\n",
    "        load(({'resources': [get_existing_entities_resource_descriptor()]}, \n",
    "              [get_existing_entities_resource(stats)]))\n",
    "    ), stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foi_offices_resource = load_odata_resource('new_foi_offices')\n",
    "foi_groups_matching_resource = load_odata_resource('foi_groups_matching')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing entities (groups) from CKAN api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_entities_flow, existing_entities_stats = get_existing_entities_flow()\n",
    "existing_entities_resource = existing_entities_flow.results()[0][0]\n",
    "yaml_print(dict(existing_entities_stats))\n",
    "print(f'Loaded existing entities ({len(existing_entities_resource)} rows)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find mismatched foi office groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_entities_group_ids = {}\n",
    "existing_entities_entity_ids = {}\n",
    "\n",
    "for existing_entity in existing_entities_resource:\n",
    "    existing_entities_group_ids[existing_entity['group_id']] = existing_entity\n",
    "    existing_entities_entity_ids[existing_entity['entity_id']] = existing_entity\n",
    "    \n",
    "mismatched_entity_ids = set()\n",
    "mismatched_group_ids = set()\n",
    "    \n",
    "for foi_group_match in foi_groups_matching_resource:\n",
    "    match_group_id = foi_group_match['Column3']\n",
    "    match_entity_id = foi_group_match['entity_id']\n",
    "    if match_group_id and match_entity_id:\n",
    "        if match_entity_id not in existing_entities_entity_ids:\n",
    "            # print(f'{match_group_id} : {match_entity_id}')\n",
    "            matching_entity_by_group_id = existing_entities_group_ids.get(match_group_id)\n",
    "            matching_entity_by_entity_id = existing_entities_entity_ids.get(match_entity_id)\n",
    "            if matching_entity_by_group_id and not matching_entity_by_entity_id:\n",
    "                print(f'group {matching_entity_by_group_id[\"title\"]}: no matching entity {match_entity_id}')\n",
    "                mismatched_entity_ids.add(match_entity_id)\n",
    "                mismatched_group_ids.add(match_group_id)\n",
    "            else:\n",
    "                raise Exception()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run update_foi_offices dry run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from update_foi_offices_entities import get_foi_offices_resource, get_existing_entities, get_foi_groups_matching\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "\n",
    "DRY_RUN = True\n",
    "\n",
    "stats = defaultdict(int)\n",
    "\n",
    "existing_entities = {}\n",
    "for row in get_existing_entities(existing_entities_resource, existing_entities, stats):\n",
    "    pass\n",
    "\n",
    "for row in get_foi_groups_matching(foi_groups_matching_resource, existing_entities, stats):\n",
    "    pass\n",
    "\n",
    "foi_offices_resource_only_mismatched = [r for r in foi_offices_resource if f\"foi-office-{r['nid']}\" in mismatched_entity_ids]\n",
    "\n",
    "for row in get_foi_offices_resource(foi_offices_resource_only_mismatched, existing_entities, stats, DRY_RUN):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before updating - save the group datasets, otherwise they will be disconnected from group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "dpp run --verbose ./dump_group_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = defaultdict(int)\n",
    "for row in load_odata_resource('dump_group_datasets', resources=['group_datasets']):\n",
    "    if not row['dataset_ids']:\n",
    "        stats['0 | groups without datasets'] += 1\n",
    "    elif len(row['dataset_ids']) == 1:\n",
    "        stats['1 | groups with 1 dataset'] += 1\n",
    "    elif 1 < len(row['dataset_ids']) < 11:\n",
    "        stats['2 | groups with 2-10 datasets'] += 1\n",
    "    elif len(row['dataset_ids']) > 10:\n",
    "        stats['3 | groups with more then 10 datasets'] += 1\n",
    "yaml_print(dict(stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRY_RUN = False\n",
    "\n",
    "for row in get_foi_offices_resource(foi_offices_resource_only_mismatched, existing_entities, stats, DRY_RUN):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, environ\n",
    "import requests\n",
    "from dataflows import Flow, load\n",
    "from datapackage_pipelines_ckanext.helpers import get_plugin_configuration\n",
    "\n",
    "def restore_group_datasets(row):\n",
    "    group_id = row['group_id']\n",
    "    if group_id in mismatched_group_ids:\n",
    "        for dataset_id in row['dataset_ids']:\n",
    "            res = session.post('{}/api/3/action/member_create'.format(CKAN_URL),\n",
    "                               json=dict(id=group_id,\n",
    "                                         object=dataset_id,\n",
    "                                         object_type='package',\n",
    "                                         capacity='')).json()\n",
    "            assert res and res['success']\n",
    "\n",
    "Flow(\n",
    "    load(path.join(data_path, 'dump_group_datasets/datapackage.json'), resources=['group_datasets']),\n",
    "    restore_group_datasets\n",
    ").process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
