{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the ckan environment and requests session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, environ\n",
    "import requests\n",
    "from dataflows import Flow, load\n",
    "from datapackage_pipelines_ckanext.helpers import get_plugin_configuration\n",
    "\n",
    "config = get_plugin_configuration('odata_org_il')\n",
    "data_path = config['data_path']\n",
    "\n",
    "CKAN_API_KEY = environ.get('CKAN_API_KEY')\n",
    "CKAN_URL = environ.get('CKAN_URL')\n",
    "assert CKAN_API_KEY and CKAN_URL\n",
    "CKAN_AUTH_HEADERS = {'Authorization': CKAN_API_KEY}\n",
    "session = requests.session()\n",
    "session.headers.update(CKAN_AUTH_HEADERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source entity data from foi site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflows import Flow, load\n",
    "import yaml\n",
    "\n",
    "def process(rows):\n",
    "    for row in rows:\n",
    "        if int(row['nid']) == 446:\n",
    "            print(yaml.dump(row, default_flow_style=False, allow_unicode=True))\n",
    "            yield row\n",
    "\n",
    "source_entity = Flow(\n",
    "    load(data_path+'/new_foi_offices/datapackage.json'),\n",
    "    process\n",
    ").results()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching ckan group from foi_groups_matching excel resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflows import Flow, load\n",
    "import yaml\n",
    "\n",
    "def process(rows):\n",
    "    for i, row in enumerate(rows):\n",
    "        if row['entity_id'] == f'foi-office-{source_entity[\"nid\"]}':\n",
    "            yield row\n",
    "\n",
    "foi_group_matching_resource = Flow(load(data_path+'/foi_groups_matching/datapackage.json')).results()[0][0]\n",
    "foi_group_matching_source_entity = [row for row in foi_group_matching_resource if row['entity_id'] == f'foi-office-{source_entity[\"nid\"]}'][0]\n",
    "print(yaml.dump(foi_group_matching_source_entity, default_flow_style=False, allow_unicode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load existing entities and find matching group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataflows import Flow, load\n",
    "from load_existing_entities import get_existing_entities_resource, get_existing_entities_resource_descriptor\n",
    "from collections import defaultdict\n",
    "\n",
    "stats = defaultdict(int)\n",
    "existing_entities_resource = Flow(load(({'resources': [get_existing_entities_resource_descriptor()]}, \n",
    "                                        [get_existing_entities_resource(stats)]))\n",
    "                                 ).results()[0][0]\n",
    "existing_entity = [row for row in existing_entities_resource if row['group_id'] == foi_group_matching_source_entity['Column3']][0]\n",
    "print(yaml.dump(existing_entity, default_flow_style=False, allow_unicode=True))\n",
    "print(f'num existing entities = {len(existing_entities)}')\n",
    "print(dict(stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run dry run to update_foi_offices_entities manually only for this group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from update_foi_offices_entities import get_foi_offices_resource, get_existing_entities, get_foi_groups_matching\n",
    "from collections import defaultdict\n",
    "import yaml\n",
    "\n",
    "stats = defaultdict(int)\n",
    "\n",
    "existing_entities = {}\n",
    "for row in get_existing_entities(existing_entities_resource, existing_entities, stats):\n",
    "    pass\n",
    "\n",
    "for row in get_foi_groups_matching(foi_group_matching_resource, existing_entities, stats):\n",
    "    pass\n",
    "\n",
    "for row in get_foi_offices_resource([source_entity], existing_entities, stats, True):\n",
    "    print(yaml.dump(row, default_flow_style=False, allow_unicode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before updating - save the group datasets, otherwise they will be disconnected from group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in get_foi_offices_resource([source_entity], existing_entities, stats, False):\n",
    "    print(yaml.dump(row, default_flow_style=False, allow_unicode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, environ\n",
    "import requests\n",
    "from dataflows import Flow, load\n",
    "from datapackage_pipelines_ckanext.helpers import get_plugin_configuration\n",
    "\n",
    "def restore_group_datasets(row):\n",
    "    group_id = row['group_id']\n",
    "    if group_id == existing_entity['group_id']:\n",
    "        for dataset_id in row['dataset_ids']:\n",
    "            res = session.post('{}/api/3/action/member_create'.format(CKAN_URL),\n",
    "                               json=dict(id=group_id,\n",
    "                                         object=dataset_id,\n",
    "                                         object_type='package',\n",
    "                                         capacity='')).json()\n",
    "            assert res and res['success']\n",
    "\n",
    "Flow(\n",
    "    load(path.join(data_path, 'dump_group_datasets/datapackage.json'), resources=['group_datasets']),\n",
    "    restore_group_datasets\n",
    ").process()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
